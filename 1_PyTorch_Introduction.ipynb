{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyBoxoydMqohfMlbL5FOfK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kavya-sree/PyTorch-examples/blob/main/1_PyTorch_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch is an open source machine learning framework originally developed by Meta AI. In September 2022, Meta shifted management to the newly created PyTorch Foundation, a subsidiary of Linux Foundation\n",
        "\n",
        "PyTorch 2.0 has been released on 15 March 2023.\n",
        "\n",
        "# Pytorch installation\n",
        "\n",
        "PyTorch can be easily installed through their official website. [PyTorch installation](https://pytorch.org/get-started/locally/). Follow along the instructions."
      ],
      "metadata": {
        "id": "-zxH8D68iNoB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "V6Zh_7rEgtgr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9cca732-a470-4f47-970d-8df7da29bd3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116\n"
          ]
        }
      ],
      "source": [
        "# Importing PyTorch\n",
        "import torch\n",
        "\n",
        "#Check PyTorch version\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch CUDA support\n",
        "PyTorch provides support for CUDA. \n",
        "\n",
        "**CUDA**\n",
        "\n",
        "To accelerate the training of our model, we can make use of hardware accelerators like GPUs (Graphical Processing Units). If you have NVIDIA GPUs, then you can use Compute Unified Device Architecture(CUDA) API.\n",
        "\n",
        "CUDA is a parallel computing platform and application programming interface (API) developed by NVIDIA for general computing on graphical processing units (GPUs). With CUDA, softwares can use certain types of graphics processing units (GPUs) for general purpose processing, an approach called general-purpose computing on GPUs (GPGPU). This speeds up computing applications.\n",
        "\n",
        "`torch.cuda` library is used to set up and run CUDA operations. It keeps track of the currently selected GPU, and all CUDA tensors you allocate will by default be created on that device. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TWrxzGhS0TQd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check CUDA availability**\n",
        "\n",
        "Before you start using CUDA, you need to check if you have CUDA available in your environment. You can check it by using the torch.cuda.is_available() function.\n",
        "\n",
        "`torch.cuda.is_available()`: Returns a bool indicating if CUDA is currently available."
      ],
      "metadata": {
        "id": "IorxrUFPmvoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh8Ku-CE9jlp",
        "outputId": "752ee924-3a3a-44d0-fd9f-3e292dee1956"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check CUDA version\n",
        "print(torch.version.cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGa1Th34TwuG",
        "outputId": "754a4ef2-3087-4774-8568-f74d88029a3c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.6\n"
          ]
        }
      ]
    }
  ]
}