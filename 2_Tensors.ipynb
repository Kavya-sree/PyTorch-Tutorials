{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVXnacLouEZQ"
   },
   "source": [
    "# Tensor\n",
    "Tensors are the building blocks in PyTorch.\n",
    "\n",
    "A tensor is a N-dimensional matrix.:\n",
    "* A scalar is a 0-dimensioanl tensor\n",
    "* A vector is a 1-dimensional or first order tensor\n",
    "* A matrix is a 2-dimensional or second order tensor.\n",
    "\n",
    "A Tensor is a generalization of vectors and matrices to higher dimensions.\n",
    "\n",
    "Many operations that we use to perform on scalars, vectors, and matrices can be performed on tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uhy4x4BvuMzh"
   },
   "source": [
    "# What exactly is Tensor??\n",
    "\n",
    "If tensors are just a generalization of matrices to higher dimensions, why not just call it \"multi-dimensional arrays\"? \n",
    "\n",
    "The answer is \"PyTorch Tensor can run on either CPU or GPU\". Thus Tensors are not just multi-dimensional arrays, they can also run on a GPU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwYL2Lk93lLc"
   },
   "source": [
    "# NumPy vs PyTorch Tensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "wxggIAOF5C5O"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t3ZO79wR51Ld",
    "outputId": "1a8d8634-be8c-489e-c380-112ac157f848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Array: [1 2 3]\n",
      "PyTorch Tensor: tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# initializing 1D array and 1D Tensor\n",
    "\n",
    "a = np.array([1, 2, 3])\n",
    "print(f'NumPy Array: {a}')\n",
    "\n",
    "b = torch.tensor([1, 2, 3])\n",
    "print(f'PyTorch Tensor: {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03QCsRJ46AXY",
    "outputId": "1f8e85a0-b47f-4385-bd4e-5a7ca4e596ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Array:\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "PyTorch Tensor:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# initializing 2D arrays and 2D tensors\n",
    "\n",
    "c = np.array([[1, 2, 3],\n",
    "              [4, 5, 6]])\n",
    "print(f'NumPy Array:\\n{c}')\n",
    "\n",
    "d = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "print(f'\\nPyTorch Tensor:\\n{d}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3WTe3lZ6UFZ"
   },
   "source": [
    "We can see somewhat similar syntax. Lets check performance.\n",
    "\n",
    "To compare the performance between NumPy arrays and PyTorch tensors on matrix multiplication we randomly initialize arrays/tensors and multiply them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "dQcYYnEt7UL2"
   },
   "outputs": [],
   "source": [
    "# 4D arrays\n",
    "array1 = np.random.rand(100, 100, 100, 100)\n",
    "array2 = np.random.rand(100, 100, 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-aQidDSo7fsC",
    "outputId": "64862a54-3b4f-4fc4-9487-0b6d1dbe5d13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3 s ± 60.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.matmul(array1, array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "1PpYSot36k5w",
    "outputId": "4ab29b64-05ad-4ce6-d995-b9c3ecda80df"
   },
   "outputs": [],
   "source": [
    "# Transferring tensor to GPU\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "tensor1 = torch.rand(100, 100, 100, 100).to(device)\n",
    "tensor2 = torch.rand(100, 100, 100, 100).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "bNXw_sK48oHx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.7 ms ± 69.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "torch.matmul(tensor1, tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kudeSKG9dfx"
   },
   "source": [
    "We can clearly see that PyTorch Tensors outperformed NumPy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNWe8ZHv-Sm1"
   },
   "source": [
    "# Creating Tensors\n",
    "\n",
    "We can start coding from the basics. \n",
    "\n",
    "A **scalar** contains a single value. We can say it is a 0-dimensional tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "rWFkjrj-AmdE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n",
      "scalar dimension: 0\n"
     ]
    }
   ],
   "source": [
    "# Scalar\n",
    "scalar = torch.tensor(5)\n",
    "print(scalar)\n",
    "\n",
    "# check dimension\n",
    "print(f'scalar dimension: {scalar.ndim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MaNfa59UAwnl"
   },
   "source": [
    "This means that scalar is a single number and it is of type `torch.Tensor`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yw7qbKXBOIt"
   },
   "source": [
    "A **Vector** is 1-dimensional tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "GBSKb1oHBXPp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 5, 5])\n",
      "Vector dimension: 1\n"
     ]
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([5, 5, 5])\n",
    "print(vector)\n",
    "\n",
    "# check dimension\n",
    "print(f'Vector dimension: {vector.ndim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUmsYjpYB8mD"
   },
   "source": [
    "A **Matrix** is a 2-dimensional tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "lZHQHRtnCBOT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "Matrix dimension: 2\n"
     ]
    }
   ],
   "source": [
    "Matrix = torch.tensor([[1, 2], \n",
    "                       [3, 4]])\n",
    "print(Matrix)\n",
    "\n",
    "# check dimension\n",
    "print(f'Matrix dimension: {Matrix.ndim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADoMbV1tCjkS"
   },
   "source": [
    "A **Tensor** is a generalization of vectors and matrices to higher dimensions.\n",
    "\n",
    "Lets create Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "sXFsoj-3CqU3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "Tensor dimension: 3\n"
     ]
    }
   ],
   "source": [
    "Tensor = torch.tensor([[[1, 2, 3],\n",
    "                        [4, 5, 6],\n",
    "                        [7, 8, 9]]])\n",
    "print(Tensor)\n",
    "\n",
    "# check dimension\n",
    "print(f'Tensor dimension: {Tensor.ndim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "SjlozAGpDDmj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of Tensor\n",
    "Tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8i1Rh8ADkn5"
   },
   "source": [
    "## Random Tensors\n",
    "\n",
    "It's rare to create Tensors by hand in deep learning. Instead, in a deep learning model we usually initialize random tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Ovlggmvxpfbd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8499, 0.6835, 0.1631],\n",
       "         [0.0732, 0.7884, 0.1926]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (2, 3)\n",
    "random_tensor = torch.rand(size=(2, 3))\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqtzWdX4DzVR"
   },
   "source": [
    "Every time you run the above code, you get different random values.\n",
    "\n",
    "It is a common practice to initialze tensors (such as a model's learning weights) with random values. But there are times, especially in research settings - where you want some assurance of the reproducibility of your results. By manually setting your random number generator’s seed you can achieve this.\n",
    "\n",
    "`torch.manual_seed(seed)`, set the seed of the random number generator to a fixed value, so that when you call the function, the results will be reproducible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "tplXdZUpCr87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2961, 0.5166, 0.2517],\n",
      "        [0.6886, 0.0740, 0.8665]])\n",
      "tensor([[0.1366, 0.1025, 0.1841],\n",
      "        [0.7264, 0.3153, 0.6871]])\n",
      "tensor([[0.2961, 0.5166, 0.2517],\n",
      "        [0.6886, 0.0740, 0.8665]])\n",
      "tensor([[0.1366, 0.1025, 0.1841],\n",
      "        [0.7264, 0.3153, 0.6871]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "random1 = torch.rand(2, 3)\n",
    "print(random1)\n",
    "\n",
    "random2 = torch.rand(2, 3)\n",
    "print(random2)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "random3 = torch.rand(2, 3)\n",
    "print(random3)\n",
    "\n",
    "random4 = torch.rand(2, 3)\n",
    "print(random4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that random1 and random3 generated same values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeros and ones\n",
    "\n",
    "Fillings tensors with zeros or ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.]]),)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(2, 3))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(2, 3))\n",
    "ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor information\n",
    "\n",
    "* `.shape` - shape of the tensor? (often, operations performed on two or more tensors require same shape)\n",
    "* `.dtype` - datatype of the tensor stored\n",
    "* `.device `- device the tensor stored on? (usually GPU or CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0756, 0.1966, 0.3164, 0.4017],\n",
      "        [0.1186, 0.8274, 0.3821, 0.6605],\n",
      "        [0.8536, 0.5932, 0.6367, 0.9826]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a random tensor\n",
    "tensor_1 = torch.rand(3, 4)\n",
    "\n",
    "print(tensor_1)\n",
    "print(f\"Shape of tensor: {tensor_1.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor_1.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor_1.device}\") # will default to CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor operations\n",
    "\n",
    "PyTorch operations are very similar to those of NumPy. We can work with both scalars and other tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 20, 30, 40])\n",
      "tensor([20, 30, 40, 50])\n",
      "tensor([ 0, 10, 20, 30])\n",
      "tensor([100, 200, 300, 400])\n",
      "tensor([1., 2., 3., 4.])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor  \n",
    "tensor = torch.tensor([10, 20, 30, 40])\n",
    "print(tensor)\n",
    "\n",
    "# \n",
    "# addition\n",
    "tensor_add = tensor + 10\n",
    "print(tensor_add)\n",
    "\n",
    "# substraction\n",
    "tensor_sub = tensor - 10\n",
    "print(tensor_sub)\n",
    "\n",
    "# multiplication\n",
    "tensor_mul = tensor * 10\n",
    "print(tensor_mul)\n",
    "\n",
    "# division\n",
    "tensor_div = tensor/ 10\n",
    "print(tensor_div)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply the same operations between different tensors of compatible sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_1: \n",
      " tensor([[10., 10., 10.],\n",
      "        [10., 10., 10.],\n",
      "        [10., 10., 10.]])\n",
      "tensor_2: \n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 4x3 tensor of 10s\n",
    "tensor_1 = torch.ones((3,3)) * 10\n",
    "print(f'tensor_1: \\n {tensor_1}')\n",
    "\n",
    "# Create a 3x2 tensor of 2s\n",
    "tensor_2 = torch.ones((3,3)) * 2\n",
    "print(f'tensor_2: \\n{tensor_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12., 12., 12.],\n",
       "        [12., 12., 12.],\n",
       "        [12., 12., 12.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_1 + tensor_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8., 8., 8.],\n",
       "        [8., 8., 8.],\n",
       "        [8., 8., 8.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_1 - tensor_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5.],\n",
       "        [5., 5., 5.],\n",
       "        [5., 5., 5.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_1 / tensor_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20., 20., 20.],\n",
       "        [20., 20., 20.],\n",
       "        [20., 20., 20.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_1 * tensor_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix multilpication\n",
    "\n",
    "Matrix multiplication is a common operation in machine learning and deep learning. It can be implemented by `torch.matmul` method\n",
    "\n",
    "`torch.matmul(input, other, *, out=None)` → Tensor\n",
    "here parameters:\n",
    "\n",
    "input (Tensor) – the first tensor to be multiplied\n",
    "\n",
    "other (Tensor) – the second tensor to be multiplied\n",
    "\n",
    "Keyword Arguments:\n",
    "out (Tensor, optional) – the output tensor.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32.)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_1 = torch.Tensor([1, 2, 3])\n",
    "tensor_2 = torch.Tensor([4, 5, 6])\n",
    "\n",
    "torch.matmul(tensor_1, tensor_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## min, max, mean, sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 10, 15, 20, 25, 30, 35, 40, 45])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "a = torch.arange(0, 50, 5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum: 0\n",
      "Maximum: 45\n",
      "Mean: 22.5\n",
      "Sum: 225\n"
     ]
    }
   ],
   "source": [
    "print(f\"Minimum: {a.min()}\")\n",
    "print(f\"Maximum: {a.max()}\")\n",
    "print(f\"Mean: {a.type(torch.float32).mean()}\") # won't work without float datatype\n",
    "print(f\"Sum: {a.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above can also be done using `torch` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45), tensor(0), tensor(22.5000), tensor(225))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(a), torch.min(a), torch.mean(a.type(torch.float32)), torch.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max value is at 9th position\n",
      "The min value is at 0th position\n"
     ]
    }
   ],
   "source": [
    "# Returns index of max and min values\n",
    "print(f\"The max value is at {a.argmax()}th position\")\n",
    "print(f\"The min value is at {a.argmin()}th position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change tensor datatype\n",
    "\n",
    "You can change the datatypes of tensors using `torch.Tensor.type(dtype=None)`\n",
    "\n",
    "dtype - the datatype you'd like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor and check its datatype\n",
    "tensor_1 = torch.arange(1, 20, 2)\n",
    "print(tensor_a)\n",
    "tensor_1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  3.,  5.,  7.,  9., 11., 13., 15., 17., 19.], dtype=torch.float16)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change dataype to float16\n",
    "tensor_float16 = tensor_1.type(torch.float16)\n",
    "tensor_float16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "\n",
    "a = torch.arange(1., 10.)\n",
    "a, a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.reshape()`: Returns a tensor with the same data and number of elements as input, but with the specified shape. When possible, the returned tensor will be a view of input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.reshape(a, (3, 3))\n",
    "b, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.view`: The returned tensor shares the same data and must have the same number of elements, but may have a different size. For a tensor to be viewed, the new view size must be compatible with its original size and stride\n",
    "\n",
    "both `torch.view` and `torch.reshape` are used to reshape tensors. If you just want to reshape tensors, use `torch.reshape`. If you're also concerned about memory usage and want to ensure that the two tensors share the same data, use `torch.view`. \n",
    "more details: https://stackoverflow.com/questions/49643225/whats-the-difference-between-reshape-and-view-in-pytorch/54507446#54507446"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.view(3, 3)\n",
    "c, c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "\n",
    "`torch.stack()`: Concatenates a sequence of tensors along a new dimension. All tensors need to be of the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tensor: \n",
      "tensor([1., 2., 3., 4.])\n",
      "stacked tensor: \n",
      "tensor([[1., 2., 3., 4.],\n",
      "        [1., 2., 3., 4.],\n",
      "        [1., 2., 3., 4.],\n",
      "        [1., 2., 3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# create a tensor\n",
    "a = torch.arange(1., 5.)\n",
    "print(f'original tensor: \\n{a}')\n",
    "\n",
    "# Stack tensors on top of each other\n",
    "a_stacked = torch.stack([a, a, a, a], dim=0) \n",
    "print(f'stacked tensor: \\n{a_stacked}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squeezing\n",
    "\n",
    "`torch.squeeze()`: Returns a tensor with all specified dimensions of input of size 1 removed. (i.e., removing all single dimensions from a tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tensor: \n",
      "tensor([[[[0.],\n",
      "          [0.],\n",
      "          [0.]]],\n",
      "\n",
      "\n",
      "        [[[0.],\n",
      "          [0.],\n",
      "          [0.]]]])\n",
      "original shape: torch.Size([2, 1, 3, 1])\n",
      "\n",
      "Squeezed tensor: \n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Squeezed shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# create a tensor\n",
    "a = torch.zeros(2,1,3,1)\n",
    "print(f'original tensor: \\n{a}')\n",
    "print(f\"original shape: {a.shape}\\n\")\n",
    "\n",
    "# squeezing\n",
    "a_squeezed = a.squeeze()\n",
    "print(f\"Squeezed tensor: \\n{a_squeezed}\")\n",
    "print(f\"Squeezed shape: {a_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reverse of `torch.squeeze()` you can use `torch.unsqueeze()` to add a dimension value of 1 at a specific index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squeezed tensor: tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Squeezed shape: torch.Size([2, 3])\n",
      "\n",
      "UnSqueezed tensor: \n",
      "tensor([[[0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.]]])\n",
      "UnSqueezed shape: torch.Size([2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Squeezed tensor: {a_squeezed}\")\n",
    "print(f\"Squeezed shape: {a_squeezed.shape}\\n\")\n",
    "\n",
    "## Add an extra dimension with unsqueeze\n",
    "a_unsqueezed = a_squeezed.unsqueeze(dim=1)\n",
    "print(f\"UnSqueezed tensor: \\n{a_unsqueezed}\")\n",
    "print(f\"UnSqueezed shape: {a_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permute\n",
    "\n",
    "`torch.permute(input, dims)`: Returns a view of the original tensor input with its dimensions permuted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor torch.Size([2, 3, 5])\n",
      "Permuted tensor torch.Size([5, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 3, 5)\n",
    "print(f'Original tensor {a.size()}')\n",
    "\n",
    "b = torch.permute(a, (2, 0, 1)).size()\n",
    "print(f'Permuted tensor {b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch tensors and NumPy\n",
    "\n",
    "PyTorch has functionality to interact with NumPy.\n",
    "\n",
    "`torch.from_numpy(ndarray)` - NumPy array -> PyTorch tensor (Creates a Tensor from a numpy.ndarray)\n",
    "\n",
    "`torch.Tensor.numpy()` - PyTorch tensor -> NumPy array (Returns the tensor as a NumPy ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array to Tensor\n",
    "a1 = np.array([1, 2, 3])\n",
    "t1 = torch.from_numpy(a)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to Numpy array\n",
    "\n",
    "t2 = torch.tensor([4, 5, 6])\n",
    "a2 = torch.Tensor.numpy(t2)\n",
    "a2"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
